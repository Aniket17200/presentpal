{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2339,"status":"ok","timestamp":1744032429620,"user":{"displayName":"Sam Gaikwad","userId":"14220425026948618466"},"user_tz":-330},"id":"YhFe3CJGAIiV","outputId":"0a881dc6-a24f-4431-ded6-9e5d7185b326"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Wav2Lip-GFPGAN'...\n","remote: Enumerating objects: 195, done.\u001b[K\n","remote: Counting objects: 100% (35/35), done.\u001b[K\n","remote: Compressing objects: 100% (26/26), done.\u001b[K\n","remote: Total 195 (delta 18), reused 9 (delta 9), pack-reused 160 (from 1)\u001b[K\n","Receiving objects: 100% (195/195), 29.94 MiB | 26.63 MiB/s, done.\n","Resolving deltas: 100% (39/39), done.\n","/content/Wav2Lip-GFPGAN\n"]}],"source":["!git clone https://github.com/ajay-sainy/Wav2Lip-GFPGAN.git\n","basePath = \"/content/Wav2Lip-GFPGAN\"\n","%cd {basePath}"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15506,"status":"ok","timestamp":1744032447276,"user":{"displayName":"Sam Gaikwad","userId":"14220425026948618466"},"user_tz":-330},"id":"mH7A_OaFUs8U","outputId":"1bbdebad-4ea6-4c78-ce8a-3f3a448c6dd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-04-07 13:27:13--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n","Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n","Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 89843225 (86M) [application/octet-stream]\n","Saving to: ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’\n","\n","/content/Wav2Lip-GF 100%[===================>]  85.68M   183MB/s    in 0.5s    \n","\n","2025-04-07 13:27:14 (183 MB/s) - ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n","\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q\n","From (redirected): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q&confirm=t&uuid=ba76ff21-ade9-4e2a-9db9-86c6676b4de6\n","To: /content/Wav2Lip-GFPGAN/Wav2Lip-master/checkpoints/wav2lip.pth\n","100% 436M/436M [00:09<00:00, 44.1MB/s]\n"]}],"source":["wav2lipFolderName = 'Wav2Lip-master'\n","gfpganFolderName = 'GFPGAN-master'\n","wav2lipPath = basePath + '/' + wav2lipFolderName\n","gfpganPath = basePath + '/' + gfpganFolderName\n","\n","!wget 'https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth' -O {wav2lipPath}'/face_detection/detection/sfd/s3fd.pth'\n","!gdown https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q --output {wav2lipPath}'/checkpoints/'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1315,"status":"ok","timestamp":1744032449534,"user":{"displayName":"Sam Gaikwad","userId":"14220425026948618466"},"user_tz":-330},"id":"CAJqWQS17Qk1","outputId":"f7fe5175-2742-4dd8-e31b-ecd742761eb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Invalid requirement: 'torchvision>=>=0.8.2': Expected end or semicolon (after name and no valid version specifier)\n","    torchvision>=>=0.8.2\n","               ^ (from line 6 of requirements.txt)\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Er-UECPiVdzX","outputId":"5ca52728-2fa0-4e12-e916-0777c7a6e28d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Cloning into 'Wav2Lip-GFPGAN'...\n","remote: Enumerating objects: 195, done.\u001b[K\n","remote: Counting objects: 100% (35/35), done.\u001b[K\n","remote: Compressing objects: 100% (26/26), done.\u001b[K\n","remote: Total 195 (delta 18), reused 9 (delta 9), pack-reused 160 (from 1)\u001b[K\n","Receiving objects: 100% (195/195), 29.94 MiB | 16.28 MiB/s, done.\n","Resolving deltas: 100% (40/40), done.\n","/content/Wav2Lip-GFPGAN\n","--2025-02-17 19:16:30--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n","Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n","Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 89843225 (86M) [application/octet-stream]\n","Saving to: ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’\n","\n","/content/Wav2Lip-GF 100%[===================>]  85.68M  18.7MB/s    in 5.7s    \n","\n","2025-02-17 19:16:37 (15.0 MB/s) - ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n","\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q\n","From (redirected): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q&confirm=t&uuid=7810e472-718c-4cdf-8174-51f723f9e35b\n","To: /content/Wav2Lip-GFPGAN/Wav2Lip-master/checkpoints/wav2lip.pth\n","100% 436M/436M [00:08<00:00, 52.4MB/s]\n","\u001b[31mERROR: Invalid requirement: 'torchvision>=>=0.8.2': Expected end or semicolon (after name and no valid version specifier)\n","    torchvision>=>=0.8.2\n","               ^ (from line 6 of requirements.txt)\u001b[0m\u001b[31m\n","\u001b[0m * Running on https://78a9-34-87-134-143.ngrok-free.app\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on all addresses (0.0.0.0)\n"," * Running on http://127.0.0.1:5000\n"," * Running on http://172.28.0.12:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Using cuda for inference.\n","Reading video frames...\n","Number of frames available for inference: 169\n","(80, 1266)\n","Length of mel chunks: 392\n","  0% 0/4 [00:00<?, ?it/s]/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model_weights = torch.load(path_to_detector)\n","\n","  0% 0/11 [00:00<?, ?it/s]\u001b[A\n","  9% 1/11 [00:05<00:50,  5.05s/it]\u001b[A\n"," 18% 2/11 [00:05<00:19,  2.21s/it]\u001b[A\n"," 27% 3/11 [00:05<00:10,  1.30s/it]\u001b[A\n"," 36% 4/11 [00:05<00:06,  1.14it/s]\u001b[A\n"," 45% 5/11 [00:05<00:03,  1.57it/s]\u001b[A\n"," 55% 6/11 [00:06<00:02,  1.99it/s]\u001b[A\n"," 64% 7/11 [00:06<00:01,  2.40it/s]\u001b[A\n"," 73% 8/11 [00:06<00:01,  2.73it/s]\u001b[A\n"," 82% 9/11 [00:06<00:00,  2.99it/s]\u001b[A\n"," 91% 10/11 [00:07<00:00,  3.23it/s]\u001b[A\n","100% 11/11 [00:09<00:00,  1.16it/s]\n","Load checkpoint from: checkpoints/wav2lip.pth\n","/content/Wav2Lip-GFPGAN/Wav2Lip-master/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path)\n","Model loaded\n","100% 4/4 [00:27<00:00,  6.86s/it]\n","ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n","\u001b[0mInput #0, wav, from '/content/Wav2Lip-GFPGAN/inputs/indic_tts_out_6.wav':\n","  Duration: 00:00:15.81, bitrate: 705 kb/s\n","  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n","Input #1, avi, from 'temp/result.avi':\n","  Metadata:\n","    software        : Lavf59.27.100\n","  Duration: 00:00:15.68, start: 0.000000, bitrate: 278 kb/s\n","  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 256x256 [SAR 1:1 DAR 1:1], 271 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n","Stream mapping:\n","  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n","  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n","\u001b[0m\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0musing SAR=1/1\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mprofile High, level 1.3, 4:2:0, 8-bit\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to '/content/Wav2Lip-GFPGAN/outputs/result.mp4':\n","  Metadata:\n","    encoder         : Lavf58.76.100\n","  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 256x256 [SAR 1:1 DAR 1:1], q=2-31, 25 fps, 12800 tbn\n","    Metadata:\n","      encoder         : Lavc58.134.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n","  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s\n","    Metadata:\n","      encoder         : Lavc58.134.100 aac\n","frame=  392 fps=257 q=-1.0 Lsize=     415kB time=00:00:15.78 bitrate= 215.3kbits/s speed=10.4x    \n","video:268kB audio:134kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.205963%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mframe I:3     Avg QP:18.65  size:  5139\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mframe P:261   Avg QP:22.47  size:   877\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mframe B:128   Avg QP:24.89  size:   228\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mconsecutive B-frames: 51.8% 10.2% 11.5% 26.5%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mmb I  I16..4: 15.9% 76.7%  7.4%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mmb P  I16..4:  1.3%  5.1%  0.0%  P16..4: 42.3% 14.1%  5.9%  0.0%  0.0%    skip:31.2%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mmb B  I16..4:  0.4%  1.5%  0.0%  B16..8: 37.1%  2.3%  0.2%  direct: 0.6%  skip:58.0%  L0:48.8% L1:46.9% BI: 4.3%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0m8x8 transform intra:78.6% inter:81.5%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mcoded y,uvDC,uvAC intra: 42.3% 53.7% 13.2% inter: 13.5% 14.9% 0.4%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mi16 v,h,dc,p: 33% 22% 41%  5%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 21% 48%  1%  2%  1%  2%  1%  3%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 17% 23%  5%  6%  8%  8%  3%  7%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mi8c dc,h,v,p: 57% 22% 18%  2%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mWeighted P-Frames: Y:3.4% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mref P L0: 68.3% 18.1% 10.2%  3.3%  0.1%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mref B L0: 88.3%  9.7%  2.0%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mref B L1: 97.8%  2.2%\n","\u001b[1;36m[libx264 @ 0x5876284a3f00] \u001b[0mkb/s:139.59\n","\u001b[1;36m[aac @ 0x5876284a9980] \u001b[0mQavg: 117.485\n"]},{"name":"stderr","output_type":"stream","text":["INFO:werkzeug:127.0.0.1 - - [17/Feb/2025 19:19:19] \"POST /process HTTP/1.1\" 200 -\n"]}],"source":["# Install required libraries\n","!pip install flask pyngrok gdown\n","\n","# Clone the repository\n","!git clone https://github.com/ajay-sainy/Wav2Lip-GFPGAN.git\n","\n","# Set the base path\n","basePath = \"/content/Wav2Lip-GFPGAN\"\n","%cd {basePath}\n","\n","# Define folder names\n","wav2lipFolderName = 'Wav2Lip-master'\n","gfpganFolderName = 'GFPGAN-master'\n","\n","# Define paths\n","wav2lipPath = basePath + '/' + wav2lipFolderName\n","gfpganPath = basePath + '/' + gfpganFolderName\n","\n","# Download the pretrained model for face detection\n","!wget 'https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth' -O {wav2lipPath}/face_detection/detection/sfd/s3fd.pth\n","\n","# Download the Wav2Lip pretrained model\n","!gdown https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q --output {wav2lipPath}/checkpoints/wav2lip.pth\n","\n","# Install dependencies\n","!pip install -r requirements.txt\n","\n","# Import necessary libraries\n","from flask import Flask, request, jsonify, send_file\n","import os\n","from werkzeug.utils import secure_filename\n","from pyngrok import ngrok\n","\n","# Initialize Flask app\n","app = Flask(__name__)\n","\n","# Set up paths\n","inputPath = basePath + '/inputs'\n","outputPath = basePath + '/outputs'\n","\n","# Create input and output directories if they don't exist\n","if not os.path.exists(inputPath):\n","    os.makedirs(inputPath)\n","if not os.path.exists(outputPath):\n","    os.makedirs(outputPath)\n","\n","# Define allowed file extensions\n","ALLOWED_EXTENSIONS = {'mp4', 'wav'}\n","\n","# Function to check if a file has an allowed extension\n","def allowed_file(filename):\n","    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n","\n","# Flask route to handle file upload and processing\n","@app.route('/process', methods=['POST'])\n","def process_files():\n","    # Check if files are present in the request\n","    if 'video' not in request.files or 'audio' not in request.files:\n","        return jsonify({\"error\": \"Both video and audio files are required\"}), 400\n","\n","    video_file = request.files['video']\n","    audio_file = request.files['audio']\n","\n","    # Check if files have valid extensions\n","    if not allowed_file(video_file.filename) or not allowed_file(audio_file.filename):\n","        return jsonify({\"error\": \"Invalid file type. Only .mp4 and .wav files are allowed\"}), 400\n","\n","    # Save the uploaded files\n","    video_path = os.path.join(inputPath, secure_filename(video_file.filename))\n","    audio_path = os.path.join(inputPath, secure_filename(audio_file.filename))\n","    video_file.save(video_path)\n","    audio_file.save(audio_path)\n","\n","    # Define the output path for the lip-synced video\n","    lipSyncedOutputPath = os.path.join(outputPath, 'result.mp4')\n","\n","    # Run the Wav2Lip inference\n","    !cd {wav2lipPath} && python inference.py \\\n","        --checkpoint_path checkpoints/wav2lip.pth \\\n","        --face {video_path} \\\n","        --audio {audio_path} \\\n","        --outfile {lipSyncedOutputPath}\n","\n","    # Return the output file as a downloadable link\n","    return send_file(lipSyncedOutputPath, as_attachment=True)\n","\n","# Start the Flask server\n","if __name__ == '__main__':\n","    # Set your ngrok token here\n","    ngrok.set_auth_token(\"2rrH36aY2OjghIDbMHyH1e9TO8u_674w937bU9yjRn69FhMVX\")\n","\n","    # Expose the Flask app via ngrok\n","    public_url = ngrok.connect(5000).public_url\n","    print(f\" * Running on {public_url}\")\n","\n","    # Run the Flask app\n","    app.run(host='0.0.0.0', port=5000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6L7v0gELLQwg","outputId":"67cbb5e7-9719-4dbe-e790-2c9a5b11c08d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Collecting pyngrok\n","  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.2.3\n","Cloning into 'Wav2Lip-GFPGAN'...\n","remote: Enumerating objects: 195, done.\u001b[K\n","remote: Counting objects: 100% (35/35), done.\u001b[K\n","remote: Compressing objects: 100% (26/26), done.\u001b[K\n","remote: Total 195 (delta 18), reused 9 (delta 9), pack-reused 160 (from 1)\u001b[K\n","Receiving objects: 100% (195/195), 29.94 MiB | 38.51 MiB/s, done.\n","Resolving deltas: 100% (39/39), done.\n","/content/Wav2Lip-GFPGAN\n","--2025-04-07 13:27:54--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n","Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n","Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 89843225 (86M) [application/octet-stream]\n","Saving to: ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’\n","\n","/content/Wav2Lip-GF 100%[===================>]  85.68M   200MB/s    in 0.4s    \n","\n","2025-04-07 13:27:55 (200 MB/s) - ‘/content/Wav2Lip-GFPGAN/Wav2Lip-master/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n","\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q\n","From (redirected): https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q&confirm=t&uuid=2b3e29bd-7a36-4cde-9341-6f7ead48dceb\n","To: /content/Wav2Lip-GFPGAN/Wav2Lip-master/checkpoints/wav2lip.pth\n","100% 436M/436M [00:19<00:00, 22.5MB/s]\n","\u001b[31mERROR: Invalid requirement: 'torchvision>=>=0.8.2': Expected end or semicolon (after name and no valid version specifier)\n","    torchvision>=>=0.8.2\n","               ^ (from line 6 of requirements.txt)\u001b[0m\u001b[31m\n"," * Running on https://06f7-34-141-163-183.ngrok-free.app\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on all addresses (0.0.0.0)\n"," * Running on http://127.0.0.1:5000\n"," * Running on http://172.28.0.12:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug:127.0.0.1 - - [07/Apr/2025 13:43:35] \"POST /process HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [07/Apr/2025 13:44:15] \"POST /process HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [07/Apr/2025 13:44:52] \"POST /process HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [07/Apr/2025 13:45:33] \"POST /process HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [07/Apr/2025 13:46:16] \"POST /process HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [07/Apr/2025 13:46:33] \"POST /process HTTP/1.1\" 200 -\n"]}],"source":["# Install required libraries\n","!pip install flask pyngrok gdown\n","\n","# Clone the repository\n","!git clone https://github.com/ajay-sainy/Wav2Lip-GFPGAN.git\n","\n","# Set the base path\n","basePath = \"/content/Wav2Lip-GFPGAN\"\n","%cd {basePath}\n","\n","# Define folder names\n","wav2lipFolderName = 'Wav2Lip-master'\n","gfpganFolderName = 'GFPGAN-master'\n","\n","# Define paths\n","wav2lipPath = basePath + '/' + wav2lipFolderName\n","gfpganPath = basePath + '/' + gfpganFolderName\n","\n","# Download the pretrained model for face detection\n","!wget 'https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth' -O {wav2lipPath}/face_detection/detection/sfd/s3fd.pth\n","\n","# Download the Wav2Lip pretrained model\n","!gdown https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q --output {wav2lipPath}/checkpoints/wav2lip.pth\n","\n","# Install dependencies\n","!pip install -r requirements.txt\n","\n","# Import necessary libraries\n","from flask import Flask, request, jsonify, send_file\n","import os\n","from werkzeug.utils import secure_filename\n","from pyngrok import ngrok\n","from concurrent.futures import ProcessPoolExecutor\n","import subprocess\n","import uuid\n","import logging\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# Initialize Flask app\n","app = Flask(__name__)\n","\n","# Set up paths\n","inputPath = basePath + '/inputs'\n","outputPath = basePath + '/outputs'\n","\n","# Create input and output directories if they don’t exist\n","os.makedirs(inputPath, exist_ok=True)\n","os.makedirs(outputPath, exist_ok=True)\n","\n","# Define allowed file extensions\n","ALLOWED_EXTENSIONS = {'mp4', 'wav'}\n","\n","# Function to check if a file has an allowed extension\n","def allowed_file(filename):\n","    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n","\n","# Initialize process pool with max_workers=1 to limit concurrent inference processes\n","executor = ProcessPoolExecutor(max_workers=1)\n","\n","# Function to run Wav2Lip inference\n","def run_inference(video_path, audio_path, output_path):\n","    cmd = [\n","        'python', 'inference.py',\n","        '--checkpoint_path', 'checkpoints/wav2lip.pth',\n","        '--face', video_path,\n","        '--audio', audio_path,\n","        '--outfile', output_path\n","    ]\n","    subprocess.run(cmd, cwd=wav2lipPath, check=True)\n","\n","# Flask route to handle file upload and processing\n","@app.route('/process', methods=['POST'])\n","def process_files():\n","    logging.info(\"Received a new request\")\n","\n","    # Check if files are present in the request\n","    if 'video' not in request.files or 'audio' not in request.files:\n","        return jsonify({\"error\": \"Both video and audio files are required\"}), 400\n","\n","    video_file = request.files['video']\n","    audio_file = request.files['audio']\n","\n","    # Check if files have valid extensions\n","    if not allowed_file(video_file.filename) or not allowed_file(audio_file.filename):\n","        return jsonify({\"error\": \"Invalid file type. Only .mp4 for video and .wav for audio are allowed\"}), 400\n","\n","    # Generate a unique ID for this request to prevent file conflicts\n","    request_id = str(uuid.uuid4())\n","\n","    # Save input files with unique names\n","    video_path = os.path.join(inputPath, f\"video_{request_id}.mp4\")\n","    audio_path = os.path.join(inputPath, f\"audio_{request_id}.wav\")\n","    lipSyncedOutputPath = os.path.join(outputPath, f\"result_{request_id}.mp4\")\n","\n","    video_file.save(video_path)\n","    audio_file.save(audio_path)\n","\n","    logging.info(f\"Starting inference for request {request_id}\")\n","    future = executor.submit(run_inference, video_path, audio_path, lipSyncedOutputPath)\n","\n","    try:\n","        future.result()  # Wait for the task to complete\n","        logging.info(f\"Inference completed for request {request_id}\")\n","        if not os.path.exists(lipSyncedOutputPath):\n","            logging.error(f\"Output file not created for request {request_id}\")\n","            return jsonify({\"error\": \"Output file was not created\"}), 500\n","        return send_file(lipSyncedOutputPath, as_attachment=True)\n","    except Exception as e:\n","        logging.error(f\"Inference failed for request {request_id}: {str(e)}\")\n","        return jsonify({\"error\": f\"Inference failed: {str(e)}\"}), 500\n","\n","# Start the Flask server\n","if __name__ == '__main__':\n","    # Set your ngrok token here (replace with your own token)\n","    ngrok.set_auth_token(\"2rrH36aY2OjghIDbMHyH1e9TO8u_674w937bU9yjRn69FhMVX\")\n","\n","    # Expose the Flask app via ngrok\n","    public_url = ngrok.connect(5000).public_url\n","    print(f\" * Running on {public_url}\")\n","\n","    # Run the Flask app with threading enabled\n","    app.run(host='0.0.0.0', port=5000, threaded=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12174,"status":"ok","timestamp":1741414104705,"user":{"displayName":"Sam Gaikwad","userId":"14220425026948618466"},"user_tz":-330},"id":"EqX_2YtkUjRI","outputId":"536d97e6-5ed3-4b1b-ac86-468548c545fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda for inference.\n","Traceback (most recent call last):\n","  File \"/content/Wav2Lip-GFPGAN/Wav2Lip-master/inference.py\", line 280, in <module>\n","    main()\n","  File \"/content/Wav2Lip-GFPGAN/Wav2Lip-master/inference.py\", line 183, in main\n","    raise ValueError('--face argument must be a valid path to video/image file')\n","ValueError: --face argument must be a valid path to video/image file\n"]}],"source":["import os\n","outputPath = basePath+'/outputs'\n","inputAudioPath = basePath + '/inputs/7b4a3c5d-5043-42a2-97a3-e8cf9dd6c26c.wav'\n","inputVideoPath = basePath + '/inputs/download.mp4'\n","lipSyncedOutputPath = basePath + '/outputs/result.mp4'\n","\n","if not os.path.exists(outputPath):\n","  os.makedirs(outputPath)\n","\n","!cd $wav2lipFolderName && python inference.py \\\n","--checkpoint_path checkpoints/wav2lip.pth \\\n","--face {inputVideoPath} \\\n","--audio {inputAudioPath} \\\n","--outfile {lipSyncedOutputPath}"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/sam17202/TTS/blob/dev/Wav2Lip-GFPGAN.ipynb","timestamp":1741008091736}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}